---
title: "머신러닝 교재 실습 01"
author: "woobin"
date: '2022-03-26'
---

# 데이터 불러오기
- kaggle 데이터를 구글drive에 저장 후 연동해서 불러옴


```python
import pandas as pd
import numpy as np
from google.colab import drive
drive.mount("/content/drive")

DATA = "/content/drive/MyDrive/Colab Notebooks/data/Fish.csv"
fish = pd.read_csv(DATA)

print(fish)
# Series01 = fish.iloc[:,0]
print(fish["Species"].value_counts())
print(fish.describe())
```

    Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
        Species  Weight  Length1  Length2  Length3   Height   Width
    0     Bream   242.0     23.2     25.4     30.0  11.5200  4.0200
    1     Bream   290.0     24.0     26.3     31.2  12.4800  4.3056
    2     Bream   340.0     23.9     26.5     31.1  12.3778  4.6961
    3     Bream   363.0     26.3     29.0     33.5  12.7300  4.4555
    4     Bream   430.0     26.5     29.0     34.0  12.4440  5.1340
    ..      ...     ...      ...      ...      ...      ...     ...
    154   Smelt    12.2     11.5     12.2     13.4   2.0904  1.3936
    155   Smelt    13.4     11.7     12.4     13.5   2.4300  1.2690
    156   Smelt    12.2     12.1     13.0     13.8   2.2770  1.2558
    157   Smelt    19.7     13.2     14.3     15.2   2.8728  2.0672
    158   Smelt    19.9     13.8     15.0     16.2   2.9322  1.8792
    
    [159 rows x 7 columns]
    Perch        56
    Bream        35
    Roach        20
    Pike         17
    Smelt        14
    Parkki       11
    Whitefish     6
    Name: Species, dtype: int64
                Weight     Length1     Length2     Length3      Height       Width
    count   159.000000  159.000000  159.000000  159.000000  159.000000  159.000000
    mean    398.326415   26.247170   28.415723   31.227044    8.970994    4.417486
    std     357.978317    9.996441   10.716328   11.610246    4.286208    1.685804
    min       0.000000    7.500000    8.400000    8.800000    1.728400    1.047600
    25%     120.000000   19.050000   21.000000   23.150000    5.944800    3.385650
    50%     273.000000   25.200000   27.300000   29.400000    7.786000    4.248500
    75%     650.000000   32.700000   35.500000   39.650000   12.365900    5.584500
    max    1650.000000   59.000000   63.400000   68.000000   18.957000    8.142000
    

# 도미와 빙어 분류하기


```python
bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]
bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]

print(bream_length)
print(bream_weight)
```

    [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]
    [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]
    

## 도미의 데이터를 산점도로 표현.


```python
import matplotlib.pyplot as plt
plt.scatter(bream_length, bream_weight)  # scatter() : 산점도
plt.xlabel("weight")
plt.ylabel("length")
plt.show()
```


    
![png](Images/0326_Machine_Learning/output_5_0.png)
    



```python
smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]
print(smelt_length)
print(smelt_weight)
```

    [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
    [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]
    

## 빙어의 데이터를 산점도로 표현.


```python
import matplotlib.pyplot as plt
plt.scatter(smelt_length, smelt_weight)
plt.xlabel("weight")
plt.ylabel("length")
plt.show()
```


    
![png](Images/0326_Machine_Learning/output_8_0.png)
    



```python
length = bream_length + smelt_length
weight = bream_weight + smelt_weight
```


```python
# print(type(length))
fish_data = [[l,w]for l, w in zip(length, weight)]
print(fish_data)
```

    [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0], [29.7, 450.0], [29.7, 500.0], [30.0, 390.0], [30.0, 450.0], [30.7, 500.0], [31.0, 475.0], [31.0, 500.0], [31.5, 500.0], [32.0, 340.0], [32.0, 600.0], [32.0, 600.0], [33.0, 700.0], [33.0, 700.0], [33.5, 610.0], [33.5, 650.0], [34.0, 575.0], [34.0, 685.0], [34.5, 620.0], [35.0, 680.0], [35.0, 700.0], [35.0, 725.0], [35.0, 720.0], [36.0, 714.0], [36.0, 850.0], [37.0, 1000.0], [38.5, 920.0], [38.5, 955.0], [39.5, 925.0], [41.0, 975.0], [41.0, 950.0], [9.8, 6.7], [10.5, 7.5], [10.6, 7.0], [11.0, 9.7], [11.2, 9.8], [11.3, 8.7], [11.8, 10.0], [11.8, 9.9], [12.0, 9.8], [12.2, 12.2], [12.4, 13.4], [13.0, 12.2], [14.3, 19.7], [15.0, 19.9]]
    


```python
# 도미는 1, 빙어는 0으로 표현
fish_target = [1] * 35 + [0] * 14
print(fish_target)
```

    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
    

## 머신러닝
- 사이킷런 패키지
  - k-최근접 이웃 ( k- Nearest Neighbors)


```python
from sklearn.neighbors import KNeighborsClassifier
# sklearn : 패키지 , # neighbors ,  KNeighborsClassifier : 클래스
kn = KNeighborsClassifier()
```


```python
kn.fit(fish_data, fish_target)  # fit() : 주어진 데이터로 알고리즘 훈련
kn.score(fish_data, fish_target)  # scroe() : 0~1 ("kn이 맞춘 비율") 의 값을 반환함
# 1은 모든 데이터를 맞췄다는 의미
```




    1.0




```python
kn.predict([[30, 600]])
## (30과 600)를 가진 데이터는 도미로 규정한 1이 출력됨을 볼 수 있음.
```




    array([1])




```python
print(kn._fit_X)
print(" ")
print(kn._y)
```

    [[  25.4  242. ]
     [  26.3  290. ]
     [  26.5  340. ]
     [  29.   363. ]
     [  29.   430. ]
     [  29.7  450. ]
     [  29.7  500. ]
     [  30.   390. ]
     [  30.   450. ]
     [  30.7  500. ]
     [  31.   475. ]
     [  31.   500. ]
     [  31.5  500. ]
     [  32.   340. ]
     [  32.   600. ]
     [  32.   600. ]
     [  33.   700. ]
     [  33.   700. ]
     [  33.5  610. ]
     [  33.5  650. ]
     [  34.   575. ]
     [  34.   685. ]
     [  34.5  620. ]
     [  35.   680. ]
     [  35.   700. ]
     [  35.   725. ]
     [  35.   720. ]
     [  36.   714. ]
     [  36.   850. ]
     [  37.  1000. ]
     [  38.5  920. ]
     [  38.5  955. ]
     [  39.5  925. ]
     [  41.   975. ]
     [  41.   950. ]
     [   9.8    6.7]
     [  10.5    7.5]
     [  10.6    7. ]
     [  11.     9.7]
     [  11.2    9.8]
     [  11.3    8.7]
     [  11.8   10. ]
     [  11.8    9.9]
     [  12.     9.8]
     [  12.2   12.2]
     [  12.4   13.4]
     [  13.    12.2]
     [  14.3   19.7]
     [  15.    19.9]]
     
    [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0
     0 0 0 0 0 0 0 0 0 0 0 0]
    


```python
# 참고 데이터를 49개로 한 kn49모델
kn49 = KNeighborsClassifier(n_neighbors=49)
kn49.fit(fish_data, fish_target)
kn49.score(fish_data, fish_target)
## 49개의 데이터중 도미인 35개만 맞춘 결과를 보여줌
```




    0.7142857142857143




```python
# 참고 데이터를 5개로 한 kn49모델
kn50 = KNeighborsClassifier(n_neighbors=5)
kn50.fit(fish_data, fish_target)
kn50.score(fish_data, fish_target)
## n_neighbors 의 데이터가 17 이하일때까지 1의 결과를 출력함.
```




    1.0



# 마무리 정리
- 사이킷런 ( scikit-learn ) 패키지
  - KNeighborsClassfier() : k-최근접 이웃 분류 모델을 만듬, n_neighbors 매개변수로 이웃의 개수를 지정함. [default : 5]
  - fit() : 사이킷런을 훈련 할 때 사용함, 처음 두 매개변수로 훈련에 사용 할특성과 정답데이터를 전달
  - predict() : 사이킷런 모델을 훈련하고 예측할 때 사용, 특성 데이터만 매개변수로 받음.
  - score(): 훈련된 사이킷런 모델의 성능을 측정
