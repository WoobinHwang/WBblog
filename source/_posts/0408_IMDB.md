---
title: "IMDB리뷰"
author: "woobin"
date: '2022-04-08'
---

# 순환 신경망으로 IMDB리뷰 분류
- 주제: 긍정리뷰, 부정리뷰 분류하기
  - 텍스트 자체는 신경망에 전달하지 않음. (문자열 --> 수식에 적용 X)
  - 문자열을 수식으로 정하는 규칙이 매우 가변적임.
  - if ex)
    - He follows the cat. He loves the cat.
    - 10- 11------- 12- 13-- 10- 14---- 12- 13

    - 고양이를 따라간다. He follows the cat.
    - 10----------- 11---------- 12-- 13------- 14- 15

- RNN, LSTM 알고리즘
  - 영어권 사람들이 만듬
  - 자연어 처리와 관련된 많은 알고리즘 또한 영어권 사람들이 만듬

- 한글 != 영어 ( 언어가 다름을 인지 )
  - 성과 내려면 제품을 써야함 (=돈) (네이버 / 카카오쪽 제품)

# 데이터 불러오기


```python
from tensorflow.keras.datasets import imdb
(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words= 500)
```

    Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz
    17465344/17464789 [==============================] - 0s 0us/step
    17473536/17464789 [==============================] - 0s 0us/step
    

- 데이터 크기 확인 (1차원 배열)
- 텍스트의 길이가 다 다르기 때문에 1차원 배열로 정리되어 있음


```python
print(train_input.shape, test_input.shape)
```

    (25000,) (25000,)
    

- 문장의 길이 확인
  - 문장의 길이가 다 다름


```python
print(len(train_input[0]))
print(len(train_input[1]))
print(len(train_input[2]))
```

    218
    189
    141
    

- Raw 데이터 전처리 -> 토큰화 작업이 끝난 상황 (문자열이 숫자로 바뀜)


```python
print(train_input[0])
```

    [1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]
    

- Target 데이터 출력
  - 0은 부정 리뷰
  - 1은 긍정 리뷰


```python
# 0번째에서 19번째까지의 데이터
print(train_target[:20])
```

    [1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]
    

# 데이터셋 분리


```python
from sklearn.model_selection import train_test_split
train_input, val_input, train_target, val_target = train_test_split(
    train_input, train_target, test_size= 0.2, random_state= 42
)
```


```python
train_input.shape, train_target.shape, val_input.shape, val_target.shape
```




    ((20000,), (20000,), (5000,), (5000,))



# 데이터 시각화


```python
import numpy as np
#  컴프리헨션으로 길이를 표현하는 배열 만들기
lengths= np.array([len(x) for x in train_input])
print(np.mean(lengths), np.median(lengths), np.max(lengths))
```

    238.71364 178.0 2494
    


```python
import matplotlib.pyplot as plt
plt.hist(lengths)
plt.show()
```


    
![png](/Images/0408_IMDB/output_17_0.png)
    


    - 250이하의 길이가 대부분임을 알 수 있음.

- 짧은 단어 100개만 사용 할 예정
- 모든 길이를 100에 맞추는 '패딩'작업 실행
- 데이터의 갯수는 20000, 전체 길이는 100으로 맞춤


```python
from tensorflow.keras.preprocessing.sequence import pad_sequences
train_seq= pad_sequences(train_input, maxlen= 100)
```


```python
print(train_seq.shape)
```

    (25000, 100)
    


```python
len(train_input[0])
```




    218




```python
print(train_seq[0])
```

    [  2  33   6  22  12 215  28  77  52   5  14 407  16  82   2   8   4 107
     117   2  15 256   4   2   7   2   5   2  36  71  43   2 476  26 400 317
      46   7   4   2   2  13 104  88   4 381  15 297  98  32   2  56  26 141
       6 194   2  18   4 226  22  21 134 476  26 480   5 144  30   2  18  51
      36  28 224  92  25 104   4 226  65  16  38   2  88  12  16 283   5  16
       2 113 103  32  15  16   2  19 178  32]
    


```python
print(train_input[0][-10:])  # 음수의 인덱스로 슬라이싱 하면 끝에서부터 세기 시작함.
print()
print(train_input[0][208:])
```

    [2, 113, 103, 32, 15, 16, 2, 19, 178, 32]
    
    [2, 113, 103, 32, 15, 16, 2, 19, 178, 32]
    

    - train_seq[0]의 길이는 218로 100보다 길기때문에 패딩이 안되었음을 확인 할 수 있음


```python
val_seq = pad_sequences(val_input, maxlen= 100)
val_seq
```




    array([[ 32,   2, 225, ...,  14,  58,   2],
           [ 53,   2,   8, ...,   7,  32,   2],
           [  0,   0,   0, ...,   2,  33,  32],
           ...,
           [383,   2, 120, ...,  16,  99,  76],
           [106, 345,  12, ..., 120,   2, 156],
           [  4, 114,  21, ...,   4,   2,   2]], dtype=int32)



# 순환신경망 만들기


```python
from tensorflow import keras
model = keras.Sequential()
# 최대 길이는 100까지 패딩, imdb.load_data() 함수에서 500개의 단어만 사용하도록 지정했었음
model.add(keras.layers.SimpleRNN(8, input_shape= (100, 500)))
model.add(keras.layers.Dense(1, activation= 'sigmoid'))
```

- 원핫인코딩 적용


```python
# to_categorical(): 원핫인코딩된 배열로 반환해줌.
train_oh = keras.utils.to_categorical(train_seq)
print(train_oh.shape)
```

    (20000, 100, 500)
    

    - 정수 하나마다 500차원의 (20000, 100)의 크기로 들어가있음을 확인 할 수 있음


```python
print(train_oh[0][0][:12])
```

    [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
    


```python
# 나머지 원소에 전부 0으로 들어가있는지 확인
print(np.sum(train_oh[0][0]))
```

    1.0
    


```python
val_oh = keras.utils.to_categorical(val_seq)
print(val_oh.shape)
```

    (5000, 100, 500)
    


```python
model.summary()
```

    Model: "sequential_3"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     simple_rnn_3 (SimpleRNN)    (None, 8)                 4072      
                                                                     
     dense_3 (Dense)             (None, 1)                 9         
                                                                     
    =================================================================
    Total params: 4,081
    Trainable params: 4,081
    Non-trainable params: 0
    _________________________________________________________________
    


```python
rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)
model.compile(optimizer=rmsprop, loss='binary_crossentropy', 
              metrics=['accuracy'])

checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5', 
                                                save_best_only=True)
early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,
                                                  restore_best_weights=True)
# 원본 epochs = 100
history = model.fit(train_oh, train_target, epochs=100, batch_size=64,
                    validation_data=(val_oh, val_target),
                    callbacks=[checkpoint_cb, early_stopping_cb])
```

    Epoch 1/100
    313/313 [==============================] - 15s 44ms/step - loss: 0.5339 - accuracy: 0.7710 - val_loss: 0.5444 - val_accuracy: 0.7566
    Epoch 2/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.5241 - accuracy: 0.7762 - val_loss: 0.5373 - val_accuracy: 0.7528
    Epoch 3/100
    313/313 [==============================] - 12s 37ms/step - loss: 0.5160 - accuracy: 0.7796 - val_loss: 0.5296 - val_accuracy: 0.7576
    Epoch 4/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.5079 - accuracy: 0.7828 - val_loss: 0.5231 - val_accuracy: 0.7592
    Epoch 5/100
    313/313 [==============================] - 12s 37ms/step - loss: 0.4998 - accuracy: 0.7872 - val_loss: 0.5165 - val_accuracy: 0.7660
    Epoch 6/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4931 - accuracy: 0.7887 - val_loss: 0.5115 - val_accuracy: 0.7666
    Epoch 7/100
    313/313 [==============================] - 12s 37ms/step - loss: 0.4858 - accuracy: 0.7914 - val_loss: 0.5061 - val_accuracy: 0.7710
    Epoch 8/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4801 - accuracy: 0.7949 - val_loss: 0.5015 - val_accuracy: 0.7690
    Epoch 9/100
    313/313 [==============================] - 11s 37ms/step - loss: 0.4742 - accuracy: 0.7972 - val_loss: 0.4985 - val_accuracy: 0.7684
    Epoch 10/100
    313/313 [==============================] - 12s 38ms/step - loss: 0.4688 - accuracy: 0.7982 - val_loss: 0.4931 - val_accuracy: 0.7744
    Epoch 11/100
    313/313 [==============================] - 16s 50ms/step - loss: 0.4636 - accuracy: 0.8023 - val_loss: 0.4941 - val_accuracy: 0.7674
    Epoch 12/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4595 - accuracy: 0.8023 - val_loss: 0.4893 - val_accuracy: 0.7732
    Epoch 13/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4546 - accuracy: 0.8051 - val_loss: 0.4850 - val_accuracy: 0.7782
    Epoch 14/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4512 - accuracy: 0.8065 - val_loss: 0.4837 - val_accuracy: 0.7760
    Epoch 15/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4471 - accuracy: 0.8097 - val_loss: 0.4826 - val_accuracy: 0.7766
    Epoch 16/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4438 - accuracy: 0.8109 - val_loss: 0.4789 - val_accuracy: 0.7796
    Epoch 17/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4396 - accuracy: 0.8121 - val_loss: 0.4795 - val_accuracy: 0.7764
    Epoch 18/100
    313/313 [==============================] - 12s 38ms/step - loss: 0.4367 - accuracy: 0.8133 - val_loss: 0.4792 - val_accuracy: 0.7760
    Epoch 19/100
    313/313 [==============================] - 12s 40ms/step - loss: 0.4344 - accuracy: 0.8127 - val_loss: 0.4761 - val_accuracy: 0.7784
    Epoch 20/100
    313/313 [==============================] - 15s 47ms/step - loss: 0.4313 - accuracy: 0.8157 - val_loss: 0.4733 - val_accuracy: 0.7822
    Epoch 21/100
    313/313 [==============================] - 11s 37ms/step - loss: 0.4289 - accuracy: 0.8162 - val_loss: 0.4753 - val_accuracy: 0.7794
    Epoch 22/100
    313/313 [==============================] - 11s 35ms/step - loss: 0.4261 - accuracy: 0.8173 - val_loss: 0.4757 - val_accuracy: 0.7806
    Epoch 23/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4241 - accuracy: 0.8167 - val_loss: 0.4717 - val_accuracy: 0.7826
    Epoch 24/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4220 - accuracy: 0.8188 - val_loss: 0.4735 - val_accuracy: 0.7816
    Epoch 25/100
    313/313 [==============================] - 12s 37ms/step - loss: 0.4197 - accuracy: 0.8202 - val_loss: 0.4696 - val_accuracy: 0.7820
    Epoch 26/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4179 - accuracy: 0.8201 - val_loss: 0.4728 - val_accuracy: 0.7834
    Epoch 27/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4160 - accuracy: 0.8210 - val_loss: 0.4736 - val_accuracy: 0.7830
    Epoch 28/100
    313/313 [==============================] - 11s 36ms/step - loss: 0.4142 - accuracy: 0.8209 - val_loss: 0.4711 - val_accuracy: 0.7836
    


```python
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.show()
```


    
![png](/Images/0408_IMDB/output_37_0.png)
    


# 단어 임베딩을 사용
  - 문제점 발생: 토큰 1개를 500차원으로 늘림
    - -> 데이터 크기가 500배 커짐
  - 단어임베딩: 라벨인코딩과 비슷


```python
from tensorflow import keras
model2 = keras.Sequential()
model2.add(keras.layers.Embedding(500, 16, input_length= 100))
model2.add(keras.layers.SimpleRNN(8))
model2.add(keras.layers.Dense(1, activation= 'sigmoid'))
```


```python
model2.summary()
```

    Model: "sequential_4"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     embedding_2 (Embedding)     (None, 100, 16)           8000      
                                                                     
     simple_rnn_4 (SimpleRNN)    (None, 8)                 200       
                                                                     
     dense_4 (Dense)             (None, 1)                 9         
                                                                     
    =================================================================
    Total params: 8,209
    Trainable params: 8,209
    Non-trainable params: 0
    _________________________________________________________________
    


```python
rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)
model2.compile(optimizer=rmsprop, loss='binary_crossentropy', 
              metrics=['accuracy'])
# 임베딩으로 Change
checkpoint_cb = keras.callbacks.ModelCheckpoint('best-embedding-model.h5', 
                                                save_best_only=True)
early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,
                                                  restore_best_weights=True)
# 원본 epochs= 100
history = model2.fit(train_seq, train_target, epochs=100, batch_size=64,
                    validation_data=(val_seq, val_target),
                    callbacks=[checkpoint_cb, early_stopping_cb])
```

    Epoch 1/100
    313/313 [==============================] - 8s 22ms/step - loss: 0.6812 - accuracy: 0.5584 - val_loss: 0.6570 - val_accuracy: 0.6208
    Epoch 2/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.6334 - accuracy: 0.6675 - val_loss: 0.6146 - val_accuracy: 0.6916
    Epoch 3/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.5940 - accuracy: 0.7219 - val_loss: 0.5831 - val_accuracy: 0.7314
    Epoch 4/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.5655 - accuracy: 0.7492 - val_loss: 0.5596 - val_accuracy: 0.7450
    Epoch 5/100
    313/313 [==============================] - 7s 21ms/step - loss: 0.5455 - accuracy: 0.7593 - val_loss: 0.5461 - val_accuracy: 0.7518
    Epoch 6/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.5302 - accuracy: 0.7678 - val_loss: 0.5405 - val_accuracy: 0.7446
    Epoch 7/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.5170 - accuracy: 0.7740 - val_loss: 0.5327 - val_accuracy: 0.7492
    Epoch 8/100
    313/313 [==============================] - 7s 21ms/step - loss: 0.5076 - accuracy: 0.7765 - val_loss: 0.5195 - val_accuracy: 0.7598
    Epoch 9/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.4996 - accuracy: 0.7814 - val_loss: 0.5141 - val_accuracy: 0.7592
    Epoch 10/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4908 - accuracy: 0.7845 - val_loss: 0.5085 - val_accuracy: 0.7642
    Epoch 11/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4844 - accuracy: 0.7876 - val_loss: 0.5082 - val_accuracy: 0.7598
    Epoch 12/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4782 - accuracy: 0.7904 - val_loss: 0.4958 - val_accuracy: 0.7722
    Epoch 13/100
    313/313 [==============================] - 6s 21ms/step - loss: 0.4711 - accuracy: 0.7937 - val_loss: 0.4989 - val_accuracy: 0.7644
    Epoch 14/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4640 - accuracy: 0.7980 - val_loss: 0.4876 - val_accuracy: 0.7740
    Epoch 15/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.4607 - accuracy: 0.7991 - val_loss: 0.4833 - val_accuracy: 0.7770
    Epoch 16/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4541 - accuracy: 0.8021 - val_loss: 0.4896 - val_accuracy: 0.7682
    Epoch 17/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4496 - accuracy: 0.8054 - val_loss: 0.4753 - val_accuracy: 0.7810
    Epoch 18/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4458 - accuracy: 0.8079 - val_loss: 0.4748 - val_accuracy: 0.7790
    Epoch 19/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.4421 - accuracy: 0.8102 - val_loss: 0.4753 - val_accuracy: 0.7786
    Epoch 20/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.4390 - accuracy: 0.8127 - val_loss: 0.4717 - val_accuracy: 0.7772
    Epoch 21/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.4351 - accuracy: 0.8131 - val_loss: 0.4823 - val_accuracy: 0.7732
    Epoch 22/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4331 - accuracy: 0.8137 - val_loss: 0.4659 - val_accuracy: 0.7842
    Epoch 23/100
    313/313 [==============================] - 7s 22ms/step - loss: 0.4301 - accuracy: 0.8145 - val_loss: 0.4655 - val_accuracy: 0.7812
    Epoch 24/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4260 - accuracy: 0.8174 - val_loss: 0.4771 - val_accuracy: 0.7754
    Epoch 25/100
    313/313 [==============================] - 6s 21ms/step - loss: 0.4243 - accuracy: 0.8185 - val_loss: 0.4637 - val_accuracy: 0.7846
    Epoch 26/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.4208 - accuracy: 0.8205 - val_loss: 0.4658 - val_accuracy: 0.7834
    Epoch 27/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4185 - accuracy: 0.8222 - val_loss: 0.4652 - val_accuracy: 0.7820
    Epoch 28/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4161 - accuracy: 0.8236 - val_loss: 0.4609 - val_accuracy: 0.7866
    Epoch 29/100
    313/313 [==============================] - 7s 21ms/step - loss: 0.4136 - accuracy: 0.8249 - val_loss: 0.4642 - val_accuracy: 0.7860
    Epoch 30/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.4113 - accuracy: 0.8254 - val_loss: 0.4601 - val_accuracy: 0.7876
    Epoch 31/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4090 - accuracy: 0.8281 - val_loss: 0.4643 - val_accuracy: 0.7824
    Epoch 32/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.4076 - accuracy: 0.8286 - val_loss: 0.4622 - val_accuracy: 0.7874
    Epoch 33/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.4053 - accuracy: 0.8289 - val_loss: 0.4590 - val_accuracy: 0.7882
    Epoch 34/100
    313/313 [==============================] - 6s 21ms/step - loss: 0.4030 - accuracy: 0.8299 - val_loss: 0.4572 - val_accuracy: 0.7902
    Epoch 35/100
    313/313 [==============================] - 7s 21ms/step - loss: 0.4010 - accuracy: 0.8321 - val_loss: 0.4632 - val_accuracy: 0.7878
    Epoch 36/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.3995 - accuracy: 0.8331 - val_loss: 0.4571 - val_accuracy: 0.7914
    Epoch 37/100
    313/313 [==============================] - 6s 19ms/step - loss: 0.3973 - accuracy: 0.8347 - val_loss: 0.4621 - val_accuracy: 0.7892
    Epoch 38/100
    313/313 [==============================] - 7s 21ms/step - loss: 0.3958 - accuracy: 0.8353 - val_loss: 0.4568 - val_accuracy: 0.7916
    Epoch 39/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.3941 - accuracy: 0.8354 - val_loss: 0.4626 - val_accuracy: 0.7868
    Epoch 40/100
    313/313 [==============================] - 7s 22ms/step - loss: 0.3927 - accuracy: 0.8358 - val_loss: 0.4611 - val_accuracy: 0.7886
    Epoch 41/100
    313/313 [==============================] - 6s 20ms/step - loss: 0.3907 - accuracy: 0.8371 - val_loss: 0.4583 - val_accuracy: 0.7912
    


```python
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.show()
```


    
![png](/Images/0408_IMDB/output_42_0.png)
    


# 마무리 정리
- 키워드
  - **말뭉치**: 자연어 처리에서 사용하는 텍스트 데이터의 모음. (= 훈련 데이터셋)
  - **토큰**: 텍스트에서 공백으로 구분되는 문자열 종종 소문자로 변환하고 구둣점은 삭제
  - **원-핫 인코딩**: 어떤 클래스에 해당하는 원소만 1이고 나머지는 모두 0인 벡터
  - **단어 임베딩**: 정수로 변환된 토큰을 비교적 작은 크기의 실수 밀집 벡터로 변환. 이런 밀집 벡터는 단어 사이의 관계를 표현 할 수 있기 때문에 자연어 처리에서 좋은 성능을 발휘

- **TensorFlow 패키지**
  - **pad_sequences()**: 시퀀스 길이를 맞추기 위해 패딩을 추가. (샘플 개수, 타임스텝 개수)크기의 2차원 배열로 나옴.
    - 매개변수 maxlen: 원하는 시퀀스 길이를 지정. 지정한 값보다 긴 시퀀스는 잘리고, 짧은 시퀀스는 패딩됨.
  - **to_categorical()**: 정수 시퀀스를 원 핫 인코딩으로 변환. 토큰이나 타깃값을 원핫 인코딩 할 때 사용
  - **SumpleRNN**: 케라스의 기본 순환층 클래스
  - **Embedding**: 단어 임베딩을 위한 클래스
